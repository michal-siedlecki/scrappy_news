{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nltk stemmer with Polish stemmer version from pystempel repository (https://github.com/dzieciou/pystempel)\n",
    "\n",
    "import pandas as pd\n",
    "from stempel import StempelStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sport = pd.read_csv(r\"headers_corp.csv\",encoding='utf-8').iloc[:100]\n",
    "nonsport = pd.read_csv(r\"headers_corp.csv\",encoding='utf-8').iloc[-100:]\n",
    "df = pd.concat([sport,nonsport]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('polish.stopwords.txt', 'r') as file:\n",
    "    polish_stop_words = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Komputer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'alell', 'alez', 'all', 'ani', 'az', 'baTMda', 'baTMdaTM', 'baTMdzie', 'bardziej', 'bardzo', 'beda', 'bede', 'bedzie', 'bez', 'bo', 'bowiem', 'by', 'bya', 'byc', 'byl', 'byla', 'byli', 'bylo', 'byly', 'bynajmniej', 'cala', 'cali', 'caly', 'ci', 'ciaTM', 'cie', 'ciebie', 'co', 'cokolwiek', 'col', 'cos', 'czasami', 'czasem', 'czemu', 'czy', 'czyli', 'd', 'daleko', 'deda', 'dla', 'dlaczego', 'dlatego', 'do', 'dobrze', 'doka', 'dokad', 'dola', 'dosc', 'dullo', 'duzo', 'dwa', 'dwaj', 'dwie', 'dwoje', 'dzil', 'dzis', 'dzisiaj', 'gdy', 'gdyby', 'gdyll', 'gdyz', 'gdzie', 'gdziekolwiek', 'gdziel', 'gdzies', 'go', 'i', 'ich', 'ile', 'ill', 'im', 'inna', 'inne', 'inny', 'innych', 'iz', 'ja', 'jak', 'jakal', 'jakas', 'jakby', 'jaki', 'jakichl', 'jakichs', 'jakie', 'jakil', 'jakill', 'jakis', 'jakiz', 'jakkolwiek', 'jako', 'jakol', 'jakos', 'je', 'jeden', 'jedna', 'jednak', 'jednaklle', 'jednakze', 'jedno', 'jego', 'jej', 'jelleli', 'jelli', 'jemu', 'jesli', 'jest', 'jestem', 'jeszcze', 'jezeli', 'jull', 'juz', 'kalldy', 'kazdy', 'kiedy', 'kilka', 'kiml', 'kims', 'ktara', 'ktare', 'ktarego', 'ktarej', 'ktary', 'ktarych', 'ktarym', 'ktarzy', 'kto', 'ktokolwiek', 'ktol', 'ktora', 'ktore', 'ktorego', 'ktorej', 'ktory', 'ktorych', 'ktorym', 'ktorzy', 'ktos', 'ku', 'lat', 'lecz', 'lladen', 'lladna', 'lladne', 'lladnych', 'lle', 'lleby', 'lub', 'ma', 'maj', 'maja', 'malo', 'mam', 'mi', 'miaTMdzy', 'miedzy', 'mimo', 'mna', 'mnie', 'moga', 'moi', 'moim', 'moj', 'moja', 'moje', 'molle', 'mollliwe', 'mollna', 'moze', 'mozliwe', 'mozna', 'mu', 'musi', 'my', 'na', 'nad', 'nam', 'nami', 'nas', 'nasi', 'nasz', 'nasza', 'nasze', 'naszego', 'naszych', 'natomiast', 'natychmiast', 'nawet', 'nia', 'nic', 'nich', 'nie', 'niech', 'niego', 'niej', 'niemu', 'nigdy', 'nill', 'nim', 'nimi', 'niz', 'no', 'o', 'obok', 'od', 'okolo', 'on', 'ona', 'one', 'oni', 'ono', 'oraz', 'oto', 'owszem', 'pan', 'pana', 'pani', 'po', 'pod', 'podczas', 'pomimo', 'ponad', 'poniewall', 'poniewaz', 'powinien', 'powinna', 'powinni', 'powinno', 'poza', 'prawie', 'przeciell', 'przeciez', 'przed', 'przede', 'przedtem', 'przez', 'przy', 'rawniell', 'roku', 'rowniez', 'sa', 'sam', 'sama', 'siaTM', 'sie', 'ska', 'skad', 'soba', 'sobie', 'sposab', 'sposob', 'swoje', 'ta', 'tak', 'taka', 'taki', 'takie', 'taklle', 'takze', 'tam', 'te', 'tego', 'tej', 'tell', 'ten', 'teraz', 'to', 'toba', 'tobie', 'totell', 'totez', 'totoba', 'trzeba', 'tu', 'tutaj', 'twaj', 'twoi', 'twoim', 'twoj', 'twoja', 'twoje', 'twym', 'ty', 'tych', 'tylko', 'tym', 'u', 'w', 'wam', 'wami', 'was', 'wasz', 'wasza', 'wasze', 'we', 'wedlug', 'wiaTMc', 'wiaTMcej', 'wiele', 'wielu', 'wlalnie', 'wlasnie', 'wszyscy', 'wszystkich', 'wszystkie', 'wszystkim', 'wszystko', 'wtedy', 'wy', 'z', 'za', 'zaden', 'zadna', 'zadne', 'zadnych', 'zapewne', 'zawsze', 'ze', 'zeby', 'zeznowu', 'zl', 'znaw', 'znow', 'znowu', 'zostal'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', \\\n",
    "                     lowercase=True, stop_words=polish_stop_words)\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
